{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl2c5in1zaiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d46f9c4e-4259-4b59-9605-0f17b1c60769"
      },
      "source": [
        "%cd ~"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjuBZNa2yjjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e77d7d71-ff7f-4364-e69f-dc3970896519"
      },
      "source": [
        "!git clone https://github.com/cfotache/pytorch_objectdetecttrack"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_objectdetecttrack'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 2 (delta 0), pack-reused 33\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZECs5bqBjqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /root/pytorch_objectdetecttrack/config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24JW1ko-y1a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRtV35fvztq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d2d20a5-636f-427d-918f-e807156d184f"
      },
      "source": [
        "%cd /root/pytorch_objectdetecttrack"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/pytorch_objectdetecttrack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV7qc6ACyThC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "import os, sys, time, datetime, random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBpXSWbyVNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "75c5b233-935b-4e51-bc09-2b6ac0778188"
      },
      "source": [
        "config_path='config/yolov3.cfg'\n",
        "weights_path='config/yolov3.weights'\n",
        "class_path='config/coco.names'\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4\n",
        "# Load model and weights\n",
        "model = Darknet(config_path, img_size=img_size)\n",
        "model.load_weights(weights_path)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "classes = utils.load_classes(class_path)\n",
        "Tensor = torch.cuda.FloatTensor"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVJayZe0AFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms=transforms.Compose([transforms.Resize((imh,imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), \n",
        "              max(int((imw-imh)/2),0), max(int((imh-imw)/2),0),\n",
        "              max(int((imw-imh)/2),0)), (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.non_max_suppression(detections, 80, \n",
        "                        conf_thres, nms_thres)\n",
        "    return detections[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-vZOeoK0GbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load image and get detections\n",
        "img_path = \"images/Intersection-Counts.jpg\"\n",
        "prev_time = time.time()\n",
        "img = Image.open(img_path)\n",
        "detections = detect_image(img)\n",
        "inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n",
        "print ('Inference Time: %s' % (inference_time))\n",
        "# Get bounding-box colors\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
        "img = np.array(img)\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(1, figsize=(12,9))\n",
        "ax.imshow(img)\n",
        "pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "unpad_h = img_size - pad_y\n",
        "unpad_w = img_size - pad_x\n",
        "if detections is not None:\n",
        "    unique_labels = detections[:, -1].cpu().unique()\n",
        "    n_cls_preds = len(unique_labels)\n",
        "    bbox_colors = random.sample(colors, n_cls_preds)\n",
        "    # browse detections and draw bounding boxes\n",
        "    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
        "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
        "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
        "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
        "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
        "        color = bbox_colors[int(np.where(\n",
        "             unique_labels == int(cls_pred))[0])]\n",
        "        bbox = patches.Rectangle((x1, y1), box_w, box_h,\n",
        "             linewidth=2, edgecolor=color, facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "        plt.text(x1, y1, s=classes[int(cls_pred)], \n",
        "                color='white', verticalalignment='top',\n",
        "                bbox={'color': color, 'pad': 0})\n",
        "plt.axis('off')\n",
        "# save image\n",
        "plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"),        \n",
        "                  bbox_inches='tight', pad_inches=0.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6N5yz8y1yf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6e72183b-d416-495a-8129-94481e8808b8"
      },
      "source": [
        "pip install pytube"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/00/62118c1e9e597aed08ddf7d9a6ca45ec95147367280aba73e8b82816fec1/pytube-9.5.3-py3-none-any.whl\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-9.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zar9unxs1shg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c6f2c4a-e42e-4a0e-d4c7-07d7d38d2d12"
      },
      "source": [
        "#importing the module \n",
        "import pytube\n",
        "\n",
        "#link of the video to be downloaded https://youtu.be/SuWEtGYhdQs\n",
        "# link = \"https://www.youtube.com/watch?v=pk96gqasGBQ\"\n",
        "link=\"https://www.youtube.com/watch?v=Y1jTEyb3wiI\"\n",
        "  \n",
        "try: \n",
        "    #object creation using YouTube which was imported in the beginning \n",
        "    yt =pytube.YouTube(link) \n",
        "except: \n",
        "    print(\"Connection Error\") #to handle exception \n",
        "  \n",
        "# #filters out all the files with \"mp4\" extension \n",
        "# mp4files = yt.filter('mp4') \n",
        "stream = yt.streams.first()\n",
        "stream.download()  "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/pytorch_objectdetecttrack/Cars moving on road Stock Footage - Free Download.mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHjiRlUKBEwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.rename(r'/root/pytorch_objectdetecttrack/Cars moving on road Stock Footage - Free Download.mp4',r'/root/pytorch_objectdetecttrack/Processed_Video.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY7DEBw04MlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz9CxdIc32Cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "545036f3-41c0-469f-8d67-b49dc9fc60b1"
      },
      "source": [
        "!pip install filterpy==1.1.0"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: filterpy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy==1.1.0) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy==1.1.0) (1.17.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy==1.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy==1.1.0) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy==1.1.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy==1.1.0) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->filterpy==1.1.0) (41.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->filterpy==1.1.0) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvar6KxcLauZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "380bdd79-a0db-4c12-e9bb-344078143c83"
      },
      "source": [
        "Processed_Frames_DIR = '/root/pytorch_objectdetecttrack/Processed_Frames'\n",
        "Processed_Video_DIR = '/root/pytorch_objectdetecttrack/Processed_Video'\n",
        "os.mkdir(Processed_Frames_DIR)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-da38a540ecea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mProcessed_Frames_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/root/pytorch_objectdetecttrack/Processed_Frames'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mProcessed_Video_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/root/pytorch_objectdetecttrack/Processed_Video'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessed_Frames_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/root/pytorch_objectdetecttrack/Processed_Frames'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhIlwCSbTLFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_IfQceO1pd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videopath = 'Processed_Video.mp4'\n",
        "%pylab inline \n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "# initialize Sort object and video capture\n",
        "from sort import *\n",
        "vid = cv2.VideoCapture(videopath)\n",
        "mot_tracker = Sort()\n",
        "#while(True):\n",
        "for ii in range(300):\n",
        "    ret, frame = vid.read()\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame)\n",
        "    detections = detect_image(pilimg)\n",
        "    img = np.array(pilimg)\n",
        "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "    unpad_h = img_size - pad_y\n",
        "    unpad_w = img_size - pad_x\n",
        "    if detections is not None:\n",
        "        tracked_objects = mot_tracker.update(detections.cpu())\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "        n_cls_preds = len(unique_labels)\n",
        "        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
        "            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
        "            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
        "            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
        "            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
        "            color = colors[int(obj_id) % len(colors)]\n",
        "            color = [i * 255 for i in color]\n",
        "            cls = classes[int(cls_pred)]\n",
        "            cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h),\n",
        "                         color, 4)\n",
        "            cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60,\n",
        "                         y1), color, -1)\n",
        "            cv2.putText(frame, cls + \"-\" + str(int(obj_id)), \n",
        "                        (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                        1, (255,255,255), 3)\n",
        "    fig=figure(figsize=(12, 8))\n",
        "    # title(\"Video Stream\")\n",
        "    # imshow(frame)\n",
        "    # show()\n",
        "    name = '{0}.jpg'.format(ii)\n",
        "    cv2.imwrite(os.path.join(Processed_Frames_DIR, name), frame)\n",
        "    clear_output(wait=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "040x1hJ3ZcK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrXxuTqZUOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all image file paths to a list.\n",
        "images = list(glob.iglob(os.path.join(Processed_Frames_DIR, '*.*')))\n",
        "# Sort the images by name index.\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "images;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toXEn58nLq_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09jEvq_HMgjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outvid = os.path.join(Processed_Video_DIR,'out.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Dv61nHMVkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_video(outvid, images=images, fps=15, size=None,\n",
        "               is_color=True, format=\"FMP4\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLFksyN3M1oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(outvid) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}